{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01664caf-fe78-462d-ac71-49a1eabee80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from AHCRDataset import AHCRDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "from BaselineCNN import BaselineCNN\n",
    "from Trainer import Trainer\n",
    "import torch.nn as nn\n",
    "from Paper1 import CNN14\n",
    "from importlib import reload\n",
    "from Paper2 import CustomCNN\n",
    "from Paper3 import ArabicCharCNN\n",
    "import torchvision.models as models\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee947aae-2725-44cf-8dfb-cc9e6ec3b9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]             320\n",
      "         MaxPool2d-2           [-1, 32, 16, 16]               0\n",
      "            Conv2d-3           [-1, 64, 16, 16]          18,496\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Linear-5                  [-1, 128]         524,416\n",
      "           Dropout-6                  [-1, 128]               0\n",
      "            Linear-7                   [-1, 28]           3,612\n",
      "================================================================\n",
      "Total params: 546,844\n",
      "Trainable params: 546,844\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.47\n",
      "Params size (MB): 2.09\n",
      "Estimated Total Size (MB): 2.56\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = BaselineCNN()\n",
    "summary(model, (1, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40830e76-80fa-4f8a-9939-40671552f7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(summary_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfe28a8b-24fc-4686-b8cc-e89e62746e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]             640\n",
      "            Conv2d-2           [-1, 64, 32, 32]          36,928\n",
      "         MaxPool2d-3           [-1, 64, 16, 16]               0\n",
      "            Conv2d-4          [-1, 128, 16, 16]          73,856\n",
      "            Conv2d-5          [-1, 128, 16, 16]         147,584\n",
      "         MaxPool2d-6            [-1, 128, 8, 8]               0\n",
      "            Conv2d-7            [-1, 256, 8, 8]         295,168\n",
      "            Conv2d-8            [-1, 256, 8, 8]         590,080\n",
      "         MaxPool2d-9            [-1, 256, 4, 4]               0\n",
      "           Conv2d-10            [-1, 512, 4, 4]       1,180,160\n",
      "           Conv2d-11            [-1, 512, 4, 4]       2,359,808\n",
      "        MaxPool2d-12            [-1, 512, 2, 2]               0\n",
      "           Linear-13                 [-1, 4096]       8,392,704\n",
      "          Dropout-14                 [-1, 4096]               0\n",
      "           Linear-15                   [-1, 28]         114,716\n",
      "================================================================\n",
      "Total params: 13,191,644\n",
      "Trainable params: 13,191,644\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.17\n",
      "Params size (MB): 50.32\n",
      "Estimated Total Size (MB): 52.50\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = CNN14()\n",
    "summary(model, (1, 32, 32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75a2e5bf-bf72-40ba-ad62-f7d56452d82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]             320\n",
      "         MaxPool2d-2           [-1, 32, 16, 16]               0\n",
      "            Conv2d-3           [-1, 64, 16, 16]          18,496\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5            [-1, 128, 8, 8]          73,856\n",
      "         MaxPool2d-6            [-1, 128, 4, 4]               0\n",
      "            Conv2d-7            [-1, 256, 4, 4]         295,168\n",
      "         MaxPool2d-8            [-1, 256, 2, 2]               0\n",
      "            Linear-9                  [-1, 512]         524,800\n",
      "           Linear-10                   [-1, 28]          14,364\n",
      "================================================================\n",
      "Total params: 927,004\n",
      "Trainable params: 927,004\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.59\n",
      "Params size (MB): 3.54\n",
      "Estimated Total Size (MB): 4.13\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = CustomCNN()\n",
    "summary(model, (1, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e4425ad-7e65-410f-9098-b9c793e66f24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]             640\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "         MaxPool2d-3           [-1, 64, 16, 16]               0\n",
      "            Conv2d-4          [-1, 128, 16, 16]          73,856\n",
      "       BatchNorm2d-5          [-1, 128, 16, 16]             256\n",
      "         MaxPool2d-6            [-1, 128, 8, 8]               0\n",
      "            Conv2d-7            [-1, 256, 8, 8]         295,168\n",
      "       BatchNorm2d-8            [-1, 256, 8, 8]             512\n",
      "         MaxPool2d-9            [-1, 256, 4, 4]               0\n",
      "           Linear-10                 [-1, 4096]      16,781,312\n",
      "          Dropout-11                 [-1, 4096]               0\n",
      "           Linear-12                 [-1, 1024]       4,195,328\n",
      "          Dropout-13                 [-1, 1024]               0\n",
      "           Linear-14                  [-1, 512]         524,800\n",
      "          Dropout-15                  [-1, 512]               0\n",
      "           Linear-16                   [-1, 28]          14,364\n",
      "================================================================\n",
      "Total params: 21,886,364\n",
      "Trainable params: 21,886,364\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.05\n",
      "Params size (MB): 83.49\n",
      "Estimated Total Size (MB): 85.55\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ArabicCharCNN()\n",
    "summary(model, (1, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c962738-c8a4-42a0-8e99-0a3c90390fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = models.alexnet(weights=None)\n",
    "resnet18 = models.resnet18(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6d55251-70d1-4e60-a06d-c84b226143be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           3,136\n",
      "              ReLU-2           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-3             [-1, 64, 7, 7]               0\n",
      "            Conv2d-4            [-1, 192, 7, 7]         307,392\n",
      "              ReLU-5            [-1, 192, 7, 7]               0\n",
      "         MaxPool2d-6            [-1, 192, 3, 3]               0\n",
      "            Conv2d-7            [-1, 384, 3, 3]         663,936\n",
      "              ReLU-8            [-1, 384, 3, 3]               0\n",
      "            Conv2d-9            [-1, 256, 3, 3]         884,992\n",
      "             ReLU-10            [-1, 256, 3, 3]               0\n",
      "           Conv2d-11            [-1, 256, 3, 3]         590,080\n",
      "             ReLU-12            [-1, 256, 3, 3]               0\n",
      "        MaxPool2d-13            [-1, 256, 1, 1]               0\n",
      "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
      "          Dropout-15                 [-1, 9216]               0\n",
      "           Linear-16                 [-1, 4096]      37,752,832\n",
      "             ReLU-17                 [-1, 4096]               0\n",
      "          Dropout-18                 [-1, 4096]               0\n",
      "           Linear-19                 [-1, 4096]      16,781,312\n",
      "             ReLU-20                 [-1, 4096]               0\n",
      "           Linear-21                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 61,080,680\n",
      "Trainable params: 61,080,680\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.86\n",
      "Params size (MB): 233.00\n",
      "Estimated Total Size (MB): 233.87\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = alexnet\n",
    "model.features[0] = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "summary(model, (1, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a420f826-cb0c-41fd-afc9-a903b8eaca5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           3,136\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-11             [-1, 64, 8, 8]               0\n",
      "           Conv2d-12             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
      "             ReLU-14             [-1, 64, 8, 8]               0\n",
      "           Conv2d-15             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
      "             ReLU-17             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-18             [-1, 64, 8, 8]               0\n",
      "           Conv2d-19            [-1, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
      "             ReLU-21            [-1, 128, 4, 4]               0\n",
      "           Conv2d-22            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
      "           Conv2d-24            [-1, 128, 4, 4]           8,192\n",
      "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
      "             ReLU-26            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-27            [-1, 128, 4, 4]               0\n",
      "           Conv2d-28            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
      "             ReLU-30            [-1, 128, 4, 4]               0\n",
      "           Conv2d-31            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
      "             ReLU-33            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
      "           Conv2d-35            [-1, 256, 2, 2]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
      "             ReLU-37            [-1, 256, 2, 2]               0\n",
      "           Conv2d-38            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
      "           Conv2d-40            [-1, 256, 2, 2]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 2, 2]             512\n",
      "             ReLU-42            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-43            [-1, 256, 2, 2]               0\n",
      "           Conv2d-44            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 2, 2]             512\n",
      "             ReLU-46            [-1, 256, 2, 2]               0\n",
      "           Conv2d-47            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 2, 2]             512\n",
      "             ReLU-49            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-50            [-1, 256, 2, 2]               0\n",
      "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-53            [-1, 512, 1, 1]               0\n",
      "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
      "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-58            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
      "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-62            [-1, 512, 1, 1]               0\n",
      "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-65            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,683,240\n",
      "Trainable params: 11,683,240\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.29\n",
      "Params size (MB): 44.57\n",
      "Estimated Total Size (MB): 45.86\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = resnet18\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "summary(model, (1, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cfaec0f-4322-4e67-b6de-b0534b7d0be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           3,136\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "           Conv2d-11            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-12            [-1, 256, 8, 8]             512\n",
      "           Conv2d-13            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
      "             ReLU-15            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-16            [-1, 256, 8, 8]               0\n",
      "           Conv2d-17             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
      "             ReLU-19             [-1, 64, 8, 8]               0\n",
      "           Conv2d-20             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
      "             ReLU-22             [-1, 64, 8, 8]               0\n",
      "           Conv2d-23            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
      "             ReLU-25            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-26            [-1, 256, 8, 8]               0\n",
      "           Conv2d-27             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
      "             ReLU-29             [-1, 64, 8, 8]               0\n",
      "           Conv2d-30             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
      "             ReLU-32             [-1, 64, 8, 8]               0\n",
      "           Conv2d-33            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
      "             ReLU-35            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 128, 8, 8]          32,768\n",
      "      BatchNorm2d-38            [-1, 128, 8, 8]             256\n",
      "             ReLU-39            [-1, 128, 8, 8]               0\n",
      "           Conv2d-40            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-41            [-1, 128, 4, 4]             256\n",
      "             ReLU-42            [-1, 128, 4, 4]               0\n",
      "           Conv2d-43            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-45            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-47            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-48            [-1, 512, 4, 4]               0\n",
      "           Conv2d-49            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
      "             ReLU-51            [-1, 128, 4, 4]               0\n",
      "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
      "             ReLU-54            [-1, 128, 4, 4]               0\n",
      "           Conv2d-55            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-57            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-58            [-1, 512, 4, 4]               0\n",
      "           Conv2d-59            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-60            [-1, 128, 4, 4]             256\n",
      "             ReLU-61            [-1, 128, 4, 4]               0\n",
      "           Conv2d-62            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-63            [-1, 128, 4, 4]             256\n",
      "             ReLU-64            [-1, 128, 4, 4]               0\n",
      "           Conv2d-65            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-66            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-67            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-68            [-1, 512, 4, 4]               0\n",
      "           Conv2d-69            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-70            [-1, 128, 4, 4]             256\n",
      "             ReLU-71            [-1, 128, 4, 4]               0\n",
      "           Conv2d-72            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-73            [-1, 128, 4, 4]             256\n",
      "             ReLU-74            [-1, 128, 4, 4]               0\n",
      "           Conv2d-75            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-76            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-77            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-78            [-1, 512, 4, 4]               0\n",
      "           Conv2d-79            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-80            [-1, 128, 4, 4]             256\n",
      "             ReLU-81            [-1, 128, 4, 4]               0\n",
      "           Conv2d-82            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-83            [-1, 128, 4, 4]             256\n",
      "             ReLU-84            [-1, 128, 4, 4]               0\n",
      "           Conv2d-85            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-86            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-87            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-88            [-1, 512, 4, 4]               0\n",
      "           Conv2d-89            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-90            [-1, 128, 4, 4]             256\n",
      "             ReLU-91            [-1, 128, 4, 4]               0\n",
      "           Conv2d-92            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-93            [-1, 128, 4, 4]             256\n",
      "             ReLU-94            [-1, 128, 4, 4]               0\n",
      "           Conv2d-95            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-96            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-97            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-98            [-1, 512, 4, 4]               0\n",
      "           Conv2d-99            [-1, 128, 4, 4]          65,536\n",
      "     BatchNorm2d-100            [-1, 128, 4, 4]             256\n",
      "            ReLU-101            [-1, 128, 4, 4]               0\n",
      "          Conv2d-102            [-1, 128, 4, 4]         147,456\n",
      "     BatchNorm2d-103            [-1, 128, 4, 4]             256\n",
      "            ReLU-104            [-1, 128, 4, 4]               0\n",
      "          Conv2d-105            [-1, 512, 4, 4]          65,536\n",
      "     BatchNorm2d-106            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-107            [-1, 512, 4, 4]               0\n",
      "      Bottleneck-108            [-1, 512, 4, 4]               0\n",
      "          Conv2d-109            [-1, 128, 4, 4]          65,536\n",
      "     BatchNorm2d-110            [-1, 128, 4, 4]             256\n",
      "            ReLU-111            [-1, 128, 4, 4]               0\n",
      "          Conv2d-112            [-1, 128, 4, 4]         147,456\n",
      "     BatchNorm2d-113            [-1, 128, 4, 4]             256\n",
      "            ReLU-114            [-1, 128, 4, 4]               0\n",
      "          Conv2d-115            [-1, 512, 4, 4]          65,536\n",
      "     BatchNorm2d-116            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-117            [-1, 512, 4, 4]               0\n",
      "      Bottleneck-118            [-1, 512, 4, 4]               0\n",
      "          Conv2d-119            [-1, 256, 4, 4]         131,072\n",
      "     BatchNorm2d-120            [-1, 256, 4, 4]             512\n",
      "            ReLU-121            [-1, 256, 4, 4]               0\n",
      "          Conv2d-122            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-123            [-1, 256, 2, 2]             512\n",
      "            ReLU-124            [-1, 256, 2, 2]               0\n",
      "          Conv2d-125           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-126           [-1, 1024, 2, 2]           2,048\n",
      "          Conv2d-127           [-1, 1024, 2, 2]         524,288\n",
      "     BatchNorm2d-128           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-129           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-130           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-131            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-132            [-1, 256, 2, 2]             512\n",
      "            ReLU-133            [-1, 256, 2, 2]               0\n",
      "          Conv2d-134            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-135            [-1, 256, 2, 2]             512\n",
      "            ReLU-136            [-1, 256, 2, 2]               0\n",
      "          Conv2d-137           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-138           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-139           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-140           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-141            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-142            [-1, 256, 2, 2]             512\n",
      "            ReLU-143            [-1, 256, 2, 2]               0\n",
      "          Conv2d-144            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-145            [-1, 256, 2, 2]             512\n",
      "            ReLU-146            [-1, 256, 2, 2]               0\n",
      "          Conv2d-147           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-148           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-149           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-150           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-151            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-152            [-1, 256, 2, 2]             512\n",
      "            ReLU-153            [-1, 256, 2, 2]               0\n",
      "          Conv2d-154            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-155            [-1, 256, 2, 2]             512\n",
      "            ReLU-156            [-1, 256, 2, 2]               0\n",
      "          Conv2d-157           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-158           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-159           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-160           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-161            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-162            [-1, 256, 2, 2]             512\n",
      "            ReLU-163            [-1, 256, 2, 2]               0\n",
      "          Conv2d-164            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-165            [-1, 256, 2, 2]             512\n",
      "            ReLU-166            [-1, 256, 2, 2]               0\n",
      "          Conv2d-167           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-168           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-169           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-170           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-171            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-172            [-1, 256, 2, 2]             512\n",
      "            ReLU-173            [-1, 256, 2, 2]               0\n",
      "          Conv2d-174            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-175            [-1, 256, 2, 2]             512\n",
      "            ReLU-176            [-1, 256, 2, 2]               0\n",
      "          Conv2d-177           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-178           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-179           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-180           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-181            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-182            [-1, 256, 2, 2]             512\n",
      "            ReLU-183            [-1, 256, 2, 2]               0\n",
      "          Conv2d-184            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-185            [-1, 256, 2, 2]             512\n",
      "            ReLU-186            [-1, 256, 2, 2]               0\n",
      "          Conv2d-187           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-188           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-189           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-190           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-191            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-192            [-1, 256, 2, 2]             512\n",
      "            ReLU-193            [-1, 256, 2, 2]               0\n",
      "          Conv2d-194            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-195            [-1, 256, 2, 2]             512\n",
      "            ReLU-196            [-1, 256, 2, 2]               0\n",
      "          Conv2d-197           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-198           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-199           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-200           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-201            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-202            [-1, 256, 2, 2]             512\n",
      "            ReLU-203            [-1, 256, 2, 2]               0\n",
      "          Conv2d-204            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-205            [-1, 256, 2, 2]             512\n",
      "            ReLU-206            [-1, 256, 2, 2]               0\n",
      "          Conv2d-207           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-208           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-209           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-210           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-211            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-212            [-1, 256, 2, 2]             512\n",
      "            ReLU-213            [-1, 256, 2, 2]               0\n",
      "          Conv2d-214            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-215            [-1, 256, 2, 2]             512\n",
      "            ReLU-216            [-1, 256, 2, 2]               0\n",
      "          Conv2d-217           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-218           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-219           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-220           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-221            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-222            [-1, 256, 2, 2]             512\n",
      "            ReLU-223            [-1, 256, 2, 2]               0\n",
      "          Conv2d-224            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-225            [-1, 256, 2, 2]             512\n",
      "            ReLU-226            [-1, 256, 2, 2]               0\n",
      "          Conv2d-227           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-228           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-229           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-230           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-231            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-232            [-1, 256, 2, 2]             512\n",
      "            ReLU-233            [-1, 256, 2, 2]               0\n",
      "          Conv2d-234            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-235            [-1, 256, 2, 2]             512\n",
      "            ReLU-236            [-1, 256, 2, 2]               0\n",
      "          Conv2d-237           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-238           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-239           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-240           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-241            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-242            [-1, 256, 2, 2]             512\n",
      "            ReLU-243            [-1, 256, 2, 2]               0\n",
      "          Conv2d-244            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-245            [-1, 256, 2, 2]             512\n",
      "            ReLU-246            [-1, 256, 2, 2]               0\n",
      "          Conv2d-247           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-248           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-249           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-250           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-251            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-252            [-1, 256, 2, 2]             512\n",
      "            ReLU-253            [-1, 256, 2, 2]               0\n",
      "          Conv2d-254            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-255            [-1, 256, 2, 2]             512\n",
      "            ReLU-256            [-1, 256, 2, 2]               0\n",
      "          Conv2d-257           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-258           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-259           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-260           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-261            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-262            [-1, 256, 2, 2]             512\n",
      "            ReLU-263            [-1, 256, 2, 2]               0\n",
      "          Conv2d-264            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-265            [-1, 256, 2, 2]             512\n",
      "            ReLU-266            [-1, 256, 2, 2]               0\n",
      "          Conv2d-267           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-268           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-269           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-270           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-271            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-272            [-1, 256, 2, 2]             512\n",
      "            ReLU-273            [-1, 256, 2, 2]               0\n",
      "          Conv2d-274            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-275            [-1, 256, 2, 2]             512\n",
      "            ReLU-276            [-1, 256, 2, 2]               0\n",
      "          Conv2d-277           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-278           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-279           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-280           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-281            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-282            [-1, 256, 2, 2]             512\n",
      "            ReLU-283            [-1, 256, 2, 2]               0\n",
      "          Conv2d-284            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-285            [-1, 256, 2, 2]             512\n",
      "            ReLU-286            [-1, 256, 2, 2]               0\n",
      "          Conv2d-287           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-288           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-289           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-290           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-291            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-292            [-1, 256, 2, 2]             512\n",
      "            ReLU-293            [-1, 256, 2, 2]               0\n",
      "          Conv2d-294            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-295            [-1, 256, 2, 2]             512\n",
      "            ReLU-296            [-1, 256, 2, 2]               0\n",
      "          Conv2d-297           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-298           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-299           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-300           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-301            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-302            [-1, 256, 2, 2]             512\n",
      "            ReLU-303            [-1, 256, 2, 2]               0\n",
      "          Conv2d-304            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-305            [-1, 256, 2, 2]             512\n",
      "            ReLU-306            [-1, 256, 2, 2]               0\n",
      "          Conv2d-307           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-308           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-309           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-310           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-311            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-312            [-1, 256, 2, 2]             512\n",
      "            ReLU-313            [-1, 256, 2, 2]               0\n",
      "          Conv2d-314            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-315            [-1, 256, 2, 2]             512\n",
      "            ReLU-316            [-1, 256, 2, 2]               0\n",
      "          Conv2d-317           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-318           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-319           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-320           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-321            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-322            [-1, 256, 2, 2]             512\n",
      "            ReLU-323            [-1, 256, 2, 2]               0\n",
      "          Conv2d-324            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-325            [-1, 256, 2, 2]             512\n",
      "            ReLU-326            [-1, 256, 2, 2]               0\n",
      "          Conv2d-327           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-328           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-329           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-330           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-331            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-332            [-1, 256, 2, 2]             512\n",
      "            ReLU-333            [-1, 256, 2, 2]               0\n",
      "          Conv2d-334            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-335            [-1, 256, 2, 2]             512\n",
      "            ReLU-336            [-1, 256, 2, 2]               0\n",
      "          Conv2d-337           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-338           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-339           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-340           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-341            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-342            [-1, 256, 2, 2]             512\n",
      "            ReLU-343            [-1, 256, 2, 2]               0\n",
      "          Conv2d-344            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-345            [-1, 256, 2, 2]             512\n",
      "            ReLU-346            [-1, 256, 2, 2]               0\n",
      "          Conv2d-347           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-348           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-349           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-350           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-351            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-352            [-1, 256, 2, 2]             512\n",
      "            ReLU-353            [-1, 256, 2, 2]               0\n",
      "          Conv2d-354            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-355            [-1, 256, 2, 2]             512\n",
      "            ReLU-356            [-1, 256, 2, 2]               0\n",
      "          Conv2d-357           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-358           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-359           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-360           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-361            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-362            [-1, 256, 2, 2]             512\n",
      "            ReLU-363            [-1, 256, 2, 2]               0\n",
      "          Conv2d-364            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-365            [-1, 256, 2, 2]             512\n",
      "            ReLU-366            [-1, 256, 2, 2]               0\n",
      "          Conv2d-367           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-368           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-369           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-370           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-371            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-372            [-1, 256, 2, 2]             512\n",
      "            ReLU-373            [-1, 256, 2, 2]               0\n",
      "          Conv2d-374            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-375            [-1, 256, 2, 2]             512\n",
      "            ReLU-376            [-1, 256, 2, 2]               0\n",
      "          Conv2d-377           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-378           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-379           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-380           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-381            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-382            [-1, 256, 2, 2]             512\n",
      "            ReLU-383            [-1, 256, 2, 2]               0\n",
      "          Conv2d-384            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-385            [-1, 256, 2, 2]             512\n",
      "            ReLU-386            [-1, 256, 2, 2]               0\n",
      "          Conv2d-387           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-388           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-389           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-390           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-391            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-392            [-1, 256, 2, 2]             512\n",
      "            ReLU-393            [-1, 256, 2, 2]               0\n",
      "          Conv2d-394            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-395            [-1, 256, 2, 2]             512\n",
      "            ReLU-396            [-1, 256, 2, 2]               0\n",
      "          Conv2d-397           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-398           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-399           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-400           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-401            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-402            [-1, 256, 2, 2]             512\n",
      "            ReLU-403            [-1, 256, 2, 2]               0\n",
      "          Conv2d-404            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-405            [-1, 256, 2, 2]             512\n",
      "            ReLU-406            [-1, 256, 2, 2]               0\n",
      "          Conv2d-407           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-408           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-409           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-410           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-411            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-412            [-1, 256, 2, 2]             512\n",
      "            ReLU-413            [-1, 256, 2, 2]               0\n",
      "          Conv2d-414            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-415            [-1, 256, 2, 2]             512\n",
      "            ReLU-416            [-1, 256, 2, 2]               0\n",
      "          Conv2d-417           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-418           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-419           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-420           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-421            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-422            [-1, 256, 2, 2]             512\n",
      "            ReLU-423            [-1, 256, 2, 2]               0\n",
      "          Conv2d-424            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-425            [-1, 256, 2, 2]             512\n",
      "            ReLU-426            [-1, 256, 2, 2]               0\n",
      "          Conv2d-427           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-428           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-429           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-430           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-431            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-432            [-1, 256, 2, 2]             512\n",
      "            ReLU-433            [-1, 256, 2, 2]               0\n",
      "          Conv2d-434            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-435            [-1, 256, 2, 2]             512\n",
      "            ReLU-436            [-1, 256, 2, 2]               0\n",
      "          Conv2d-437           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-438           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-439           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-440           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-441            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-442            [-1, 256, 2, 2]             512\n",
      "            ReLU-443            [-1, 256, 2, 2]               0\n",
      "          Conv2d-444            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-445            [-1, 256, 2, 2]             512\n",
      "            ReLU-446            [-1, 256, 2, 2]               0\n",
      "          Conv2d-447           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-448           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-449           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-450           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-451            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-452            [-1, 256, 2, 2]             512\n",
      "            ReLU-453            [-1, 256, 2, 2]               0\n",
      "          Conv2d-454            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-455            [-1, 256, 2, 2]             512\n",
      "            ReLU-456            [-1, 256, 2, 2]               0\n",
      "          Conv2d-457           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-458           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-459           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-460           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-461            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-462            [-1, 256, 2, 2]             512\n",
      "            ReLU-463            [-1, 256, 2, 2]               0\n",
      "          Conv2d-464            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-465            [-1, 256, 2, 2]             512\n",
      "            ReLU-466            [-1, 256, 2, 2]               0\n",
      "          Conv2d-467           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-468           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-469           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-470           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-471            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-472            [-1, 256, 2, 2]             512\n",
      "            ReLU-473            [-1, 256, 2, 2]               0\n",
      "          Conv2d-474            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-475            [-1, 256, 2, 2]             512\n",
      "            ReLU-476            [-1, 256, 2, 2]               0\n",
      "          Conv2d-477           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-478           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-479           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-480           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-481            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-482            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-483            [-1, 512, 2, 2]               0\n",
      "          Conv2d-484            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-485            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-486            [-1, 512, 1, 1]               0\n",
      "          Conv2d-487           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-488           [-1, 2048, 1, 1]           4,096\n",
      "          Conv2d-489           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-490           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-491           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-492           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-493            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-494            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-495            [-1, 512, 1, 1]               0\n",
      "          Conv2d-496            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-497            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-498            [-1, 512, 1, 1]               0\n",
      "          Conv2d-499           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-500           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-501           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-502           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-503            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-504            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-505            [-1, 512, 1, 1]               0\n",
      "          Conv2d-506            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-507            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-508            [-1, 512, 1, 1]               0\n",
      "          Conv2d-509           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-510           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-511           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-512           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-513           [-1, 2048, 1, 1]               0\n",
      "          Linear-514                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 60,186,536\n",
      "Trainable params: 60,186,536\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 12.40\n",
      "Params size (MB): 229.59\n",
      "Estimated Total Size (MB): 242.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resnet152 = models.resnet152(weights=None)\n",
    "resnet152_model = resnet152 \n",
    "resnet152.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "summary(resnet152_model, (1, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d0d1d74-4951-4e4f-821a-2f55f369827f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ahmad/Desktop/Computer Vision/Computer-Vision-Project/EMNIST-Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmad/anaconda3/envs/torch/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd EMNIST-Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfd39748-9bbd-44c8-87cc-88059746e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from charclf.models import VGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3da51192-ca84-4ae6-a841-8d8a732b4802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGGNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1152, out_features=512, bias=True)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): Linear(in_features=512, out_features=62, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "707a9191-664b-4a6c-b1ab-79625a858b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             160\n",
      "              ReLU-2           [-1, 16, 32, 32]               0\n",
      "            Conv2d-3           [-1, 32, 32, 32]           4,640\n",
      "              ReLU-4           [-1, 32, 32, 32]               0\n",
      "         MaxPool2d-5           [-1, 32, 16, 16]               0\n",
      "            Conv2d-6           [-1, 64, 16, 16]          18,496\n",
      "              ReLU-7           [-1, 64, 16, 16]               0\n",
      "            Conv2d-8           [-1, 64, 16, 16]          36,928\n",
      "              ReLU-9           [-1, 64, 16, 16]               0\n",
      "           Conv2d-10          [-1, 128, 16, 16]          73,856\n",
      "             ReLU-11          [-1, 128, 16, 16]               0\n",
      "           Conv2d-12          [-1, 128, 16, 16]         147,584\n",
      "             ReLU-13          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
      "           Conv2d-15            [-1, 128, 8, 8]         147,584\n",
      "             ReLU-16            [-1, 128, 8, 8]               0\n",
      "           Conv2d-17            [-1, 128, 8, 8]         147,584\n",
      "             ReLU-18            [-1, 128, 8, 8]               0\n",
      "AdaptiveAvgPool2d-19            [-1, 128, 3, 3]               0\n",
      "           Linear-20                  [-1, 512]         590,336\n",
      "      BatchNorm1d-21                  [-1, 512]           1,024\n",
      "             ReLU-22                  [-1, 512]               0\n",
      "          Dropout-23                  [-1, 512]               0\n",
      "           Linear-24                  [-1, 512]         262,656\n",
      "      BatchNorm1d-25                  [-1, 512]           1,024\n",
      "             ReLU-26                  [-1, 512]               0\n",
      "          Dropout-27                  [-1, 512]               0\n",
      "           Linear-28                   [-1, 28]          14,364\n",
      "================================================================\n",
      "Total params: 1,446,236\n",
      "Trainable params: 1,446,236\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.67\n",
      "Params size (MB): 5.52\n",
      "Estimated Total Size (MB): 8.19\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "vggnet = VGGNet()\n",
    "vggnet.classifier[8] = nn.Linear(in_features=512, out_features=28, bias=True)\n",
    "summary(vggnet, (1, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5f25224-5096-417e-91ee-f1f2075682b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpinalNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (spinal_layer1): Linear(in_features=1568, out_features=50, bias=True)\n",
       "  (spinal_layer2): Linear(in_features=1618, out_features=50, bias=True)\n",
       "  (spinal_layer3): Linear(in_features=1618, out_features=50, bias=True)\n",
       "  (spinal_layer4): Linear(in_features=1618, out_features=50, bias=True)\n",
       "  (classifier): Linear(in_features=200, out_features=62, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spinalnet = SpinalNet()\n",
    "spinalnet.to(device).load_state_dict(torch.load(\"model_hub/fine_tuned/spinalnet_tuned.pth\", map_location=device))\n",
    "spinalnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6576b5c2-1632-4bb9-a1c9-ede669a2d836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
